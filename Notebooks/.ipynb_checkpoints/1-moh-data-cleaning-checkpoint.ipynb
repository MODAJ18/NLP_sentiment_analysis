{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94cedb26",
   "metadata": {},
   "source": [
    "## Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3609721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba3c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/raw_data/Train.csv\")\n",
    "val_df = pd.read_csv(\"../Data/raw_data/Valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9183bc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"Western Union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>This movie is an incredible piece of work. It ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>My wife and I watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>When I first watched Flatliners, I was amazed....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I grew up (b. 1965) watching and loving the Th...      0\n",
       "1      When I put this movie in my DVD player, and sa...      0\n",
       "2      Why do people who do not know what a particula...      0\n",
       "3      Even though I have great interest in Biblical ...      0\n",
       "4      Im a die hard Dads Army fan and nothing will e...      1\n",
       "...                                                  ...    ...\n",
       "39995  \"Western Union\" is something of a forgotten cl...      1\n",
       "39996  This movie is an incredible piece of work. It ...      1\n",
       "39997  My wife and I watched this movie because we pl...      0\n",
       "39998  When I first watched Flatliners, I was amazed....      1\n",
       "39999  Why would this film be so good, but only gross...      1\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad162436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's been about 14 years since Sharon Stone aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone needed to make a car payment... this i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Guidelines state that a comment must conta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a muddled mish-mash of clichés f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before Stan Laurel became the smaller half of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Man, I loved this movie! This really takes me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Recovery is an incredibly moving piece of work...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>You can take the crook out of the joint, but i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\"The Mother\" tells of a recently widowed mid-6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     It's been about 14 years since Sharon Stone aw...      0\n",
       "1     someone needed to make a car payment... this i...      0\n",
       "2     The Guidelines state that a comment must conta...      0\n",
       "3     This movie is a muddled mish-mash of clichés f...      0\n",
       "4     Before Stan Laurel became the smaller half of ...      0\n",
       "...                                                 ...    ...\n",
       "4995  Man, I loved this movie! This really takes me ...      1\n",
       "4996  Recovery is an incredibly moving piece of work...      1\n",
       "4997  You can take the crook out of the joint, but i...      1\n",
       "4998  FUTZ is the only show preserved from the exper...      1\n",
       "4999  \"The Mother\" tells of a recently widowed mid-6...      1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c9e702a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    20019\n",
       "1    19981\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    2514\n",
       "0    2486\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y-feature distribution\n",
    "display(train_df['label'].unique())\n",
    "display(train_df['label'].value_counts())\n",
    "\n",
    "display(val_df['label'].unique())\n",
    "display(val_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee88c2c",
   "metadata": {},
   "source": [
    "**NOTE** Even Distribution of 1 and 0, which is good for model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2fffc7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "326b0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Text Cleaning \n",
    "import re\n",
    "import nltk\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d1c37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions Defined \n",
    "# 2\n",
    "mention_re = re.compile(\"@\\w+\")\n",
    "def remove_mention(text):\n",
    "    return mention_re.sub(repl=\" \", string=text)\n",
    "\n",
    "# 3\n",
    "# Converting emojis to words\n",
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "        return text\n",
    "# Converting emoticons to words    \n",
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "        return text\n",
    "\n",
    "# 4\n",
    "def remove_urls(text):\n",
    "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', text)\n",
    "\n",
    "# 5\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").text\n",
    "\n",
    "# 6\n",
    "# removing symbols\n",
    "symb_re = re.compile(r\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~،؟…«“\\\":\\\"…”]\"\"\")\n",
    "def remove_symbols(text: str) -> str:\n",
    "    return symb_re.sub(repl=\"\", string=text)\n",
    "# removing numbers\n",
    "numbers_re = re.compile(\"\\d+\")\n",
    "def remove_numbers(text):\n",
    "    # TODO: Implement remove numbers\n",
    "    return numbers_re.sub(repl=\"\", string=text)\n",
    "\n",
    "# 7\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "# 8 \n",
    "cnt = Counter()\n",
    "for text in train_df['text'].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "# Removing the frequent words\n",
    "freq = set([w for (w, wc) in cnt.most_common(150)])\n",
    "def remove_freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not \n",
    "in freq])\n",
    "\n",
    "# 9 \n",
    "rx = re.compile(r'([^\\W\\d_])\\1{2,}')\n",
    "def remove_repeating_characters(text: str):\n",
    "    return re.sub(r'[^\\W\\d_]+', lambda x: Word(rx.sub(r'\\1\\1', x.group())).correct() \\\n",
    "                  if rx.search(x.group()) else x.group(), text)\n",
    "# 10\n",
    "multiple_space_re = re.compile(\"\\s{2,}\")\n",
    "def remove_multiple_whitespace(text):\n",
    "    return multiple_space_re.sub(repl=\" \", string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c40fb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(txt):\n",
    "    txt = remove_mention(txt)\n",
    "    # txt = convert_emojis(txt)\n",
    "    # txt = convert_emoticons(txt)\n",
    "    txt = remove_urls(txt)\n",
    "    txt = remove_html(txt)\n",
    "    txt = remove_stopwords(txt)\n",
    "    txt = remove_symbols(txt)\n",
    "    txt = remove_numbers(txt)   # might be removed as it can result in loss of information for the textual data\n",
    "    txt = re.sub(\"[^a-zA-Z0-9\\s]+\", \"\",txt)\n",
    "    # txt = remove_freqwords(txt) \n",
    "    # txt = str(TextBlob(txt).correct())  # word correction\n",
    "    txt = txt.lower().strip()\n",
    "    # txt = remove_repeating_characters(txt)\n",
    "    txt = remove_multiple_whitespace(txt)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96e0697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: no text cleaning applied\n",
    "train_df['text_cleaned'] = train_df['text'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62cfb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['text_cleaned'] = val_df['text'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9646347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"../Data/processed/Train_clean.csv\", index=False)\n",
    "val_df.to_csv(\"../Data/processed/Valid_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbd5c2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.8 GiB for an array with shape (40000, 39719) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m values \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m tfidf_feature_names \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names()\n\u001b[1;32m----> 4\u001b[0m tfidf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns \u001b[38;5;241m=\u001b[39m tfidf_feature_names)\n\u001b[0;32m      5\u001b[0m tfidf_df\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\scipy\\sparse\\compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1039\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\scipy\\sparse\\base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.8 GiB for an array with shape (40000, 39719) and data type float64"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "values = tfidf_vectorizer.fit_transform(train_df['text_cleaned'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "tfidf_df = pd.DataFrame(values.toarray(), columns = tfidf_feature_names)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d306bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tfidf_df.drop(columns=['label']), tfidf_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=110 , stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58911b17",
   "metadata": {},
   "source": [
    "## Model - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "MultinomialNB_model = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
    "LogReg_model = LogisticRegression()\n",
    "SGDClassifier_model = SGDClassifier(class_weight='balanced', penalty='l1')\n",
    "\n",
    "models = [MultinomialNB_model, LogReg_model, SGDClassifier_model]\n",
    "model_names = ['MultinomialNB', 'LogisticRegression', 'SGDClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2074d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_tr, X_te, y_tr, y_te):\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Model: {model_names[i]}\")\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_te)\n",
    "        print('accuracy %s' % accuracy_score(y_te, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc3e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dcbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataEngineeringKER",
   "language": "python",
   "name": "dataengineeringker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
