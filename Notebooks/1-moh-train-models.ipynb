{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26f0044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "597783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_clean = pd.read_csv(\"../Data/processed/Train_clean.csv\")\n",
    "val_df_clean = pd.read_csv(\"../Data/processed/Valid_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dbd5c2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_tr = tfidf_vectorizer.fit_transform(train_df_clean['text_cleaned'])\n",
    "tfidf_val = tfidf_vectorizer.transform(val_df_clean['text_cleaned'])\n",
    "# tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "# tfidf_df = pd.DataFrame(values.toarray(), columns = tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e51bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 186272), (40000,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = tfidf_tr, train_df_clean['label']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c31443f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 186272), (5000,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = tfidf_val, val_df_clean['label']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58911b17",
   "metadata": {},
   "source": [
    "## Model - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21553d72",
   "metadata": {},
   "source": [
    "### 1- ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f4d14",
   "metadata": {},
   "source": [
    "`Preprocessing`: Text -> Vectroization(default) -> tf-idf feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3013a3f",
   "metadata": {},
   "source": [
    "**NOTE**: vectorization is not used explictily as tfidf sklearn method uses word analyzer to make the vector out of text for later encoding. ngram_range used is only (1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "265f2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5643cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "LogReg_model = LogisticRegression()\n",
    "RandomForestClassifier_model = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "MultinomialNB_model = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
    "SGDClassifier_model = SGDClassifier(class_weight='balanced', penalty='l1')\n",
    "KNeighborsClassifier_model = KNeighborsClassifier(n_neighbors=3)\n",
    "DecisionTreeClassifier_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "models = [LogReg_model, RandomForestClassifier_model, DecisionTreeClassifier_model,\n",
    "          SGDClassifier_model,   \n",
    "          KNeighborsClassifier_model,  MultinomialNB_model]\n",
    "model_names = ['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier',\n",
    "               'SGDClassifier', 'KNeighborsClassifier', 'MultinomialNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2074d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_tr, X_te, y_tr, y_te):\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Model: {model_names[i]}\")\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_te)\n",
    "        print('val accuracy %s' % accuracy_score(y_te, y_pred))\n",
    "        # print(classification_report(y_te, y_pred))  # for further evaluation\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9fc3e6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "accuracy 0.8858\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "accuracy 0.782\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "accuracy 0.7148\n",
      "\n",
      "Model: SGDClassifier\n",
      "accuracy 0.86\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "accuracy 0.7798\n",
      "\n",
      "Model: MultinomialNB\n",
      "accuracy 0.862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788daa2",
   "metadata": {},
   "source": [
    "### 2- DL Models - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650be98",
   "metadata": {},
   "source": [
    "`Preprocessing`: Text -> sequence data embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3dadab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from  tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b70dad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>i grew b watching loving thunderbirds all mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>when i put movie dvd player sat coke chips i e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>why people know particular time past like feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>even though i great interest biblical movies i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>im die hard dads army fan nothing ever change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"Western Union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>western union something forgotten classic west...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>This movie is an incredible piece of work. It ...</td>\n",
       "      <td>1</td>\n",
       "      <td>this movie incredible piece work it explores e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>My wife and I watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>my wife i watched movie plan visit sicily stro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>When I first watched Flatliners, I was amazed....</td>\n",
       "      <td>1</td>\n",
       "      <td>when i first watched flatliners i amazed it ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "      <td>why would film good gross estimated no award n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1      When I put this movie in my DVD player, and sa...      0   \n",
       "2      Why do people who do not know what a particula...      0   \n",
       "3      Even though I have great interest in Biblical ...      0   \n",
       "4      Im a die hard Dads Army fan and nothing will e...      1   \n",
       "...                                                  ...    ...   \n",
       "39995  \"Western Union\" is something of a forgotten cl...      1   \n",
       "39996  This movie is an incredible piece of work. It ...      1   \n",
       "39997  My wife and I watched this movie because we pl...      0   \n",
       "39998  When I first watched Flatliners, I was amazed....      1   \n",
       "39999  Why would this film be so good, but only gross...      1   \n",
       "\n",
       "                                            text_cleaned  \n",
       "0      i grew b watching loving thunderbirds all mate...  \n",
       "1      when i put movie dvd player sat coke chips i e...  \n",
       "2      why people know particular time past like feel...  \n",
       "3      even though i great interest biblical movies i...  \n",
       "4      im die hard dads army fan nothing ever change ...  \n",
       "...                                                  ...  \n",
       "39995  western union something forgotten classic west...  \n",
       "39996  this movie incredible piece work it explores e...  \n",
       "39997  my wife i watched movie plan visit sicily stro...  \n",
       "39998  when i first watched flatliners i amazed it ne...  \n",
       "39999  why would film good gross estimated no award n...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bcf77bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = np.max(train_df_clean['text_cleaned'].apply(lambda x :len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aafa77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(oov_token  = '<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(train_df_clean['text_cleaned'])\n",
    "\n",
    "vocab_length = len(tokenizer.word_index) + 1\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('vocabulary length', vocab_length, end='\\n\\n')\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1d20337",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_df_clean['text_cleaned'])\n",
    "val_sequences = tokenizer.texts_to_sequences(val_df_clean['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ad5c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  pad_sequences(\n",
    "    sequences=train_sequences,\n",
    "    maxlen=int(max_len), \n",
    "    padding=\"pre\", \n",
    "    truncating=\"pre\", \n",
    "    value=0\n",
    ")\n",
    "y_train = train_df_clean['label'].copy()\n",
    "X_test = pad_sequences(\n",
    "    sequences=val_sequences,\n",
    "    maxlen=int(max_len), \n",
    "    padding=\"pre\", \n",
    "    truncating=\"pre\", \n",
    "    value=0\n",
    ")\n",
    "y_test = val_df_clean['label'].copy()\n",
    "\n",
    "# Is the total vocabulary size + padding token\n",
    "num_features = len(tokenizer.index_word) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bc81859e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 181s 288ms/step - loss: 0.3751 - accuracy: 0.8329 - val_loss: 0.3321 - val_accuracy: 0.8868\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 0.1566 - accuracy: 0.9448 - val_loss: 0.2800 - val_accuracy: 0.8880\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 167s 267ms/step - loss: 0.0805 - accuracy: 0.9750 - val_loss: 0.3798 - val_accuracy: 0.8852\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 167s 268ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.3956 - val_accuracy: 0.8796\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 168s 270ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.5877 - val_accuracy: 0.8666\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 169s 271ms/step - loss: 0.0561 - accuracy: 0.9789 - val_loss: 0.5163 - val_accuracy: 0.8736\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 170s 272ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 0.4921 - val_accuracy: 0.8576\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 170s 271ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.6375 - val_accuracy: 0.8704\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 170s 271ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.7043 - val_accuracy: 0.8682\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 170s 272ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.5835 - val_accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3eaa538e0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "\n",
    "lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_length, embedding_dim, input_length=max_len),\n",
    "    tf.keras.layers.LSTM(units=64, return_sequences=False),\n",
    "    # tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "lstm.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "lstm.fit(X_train, y_train, batch_size=64, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44c85c",
   "metadata": {},
   "source": [
    "Next, Work on:\n",
    "- hyperparameter tuning on best models\n",
    "- build other models (DL or ML)\n",
    "- solve overfitting issue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-tensorflow",
   "language": "python",
   "name": "dl-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
